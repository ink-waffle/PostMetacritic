{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-09-12T12:55:10.184963Z",
     "end_time": "2023-09-12T12:55:10.574978Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "from Keys import openai_keys\n",
    "import re\n",
    "\n",
    "openai.organization = openai_keys['organization']\n",
    "openai.api_key = openai_keys['api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Load the JSON data from the file\n",
    "with open('Source/reddit-oppenheimer-26.json', 'r') as json_file:\n",
    "    comments_by_post = json.load(json_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-30T20:04:29.925680Z",
     "end_time": "2023-08-30T20:04:29.944642Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class Post:\n",
    "    def __init__(self, title, analysis, raw):\n",
    "        self.title = title\n",
    "        self.analysis = analysis\n",
    "        self.raw = raw"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-30T20:04:35.740532Z",
     "end_time": "2023-08-30T20:04:35.749541Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/19\n",
      "2/19\n",
      "3/19\n",
      "4/19\n",
      "5/19\n",
      "6/19\n",
      "7/19\n",
      "8/19\n",
      "9/19\n",
      "10/19\n",
      "11/19\n",
      "12/19\n",
      "13/19\n",
      "14/19\n",
      "15/19\n",
      "16/19\n",
      "17/19\n",
      "18/19\n",
      "19/19\n"
     ]
    }
   ],
   "source": [
    "redditSentiment = list()\n",
    "iter = 0\n",
    "for title, comments in comments_by_post.items():\n",
    "    prompts = [{\"role\": \"system\", \"content\":\n",
    "        'Analyse the sentiment of 16 Reddit comments under a post - \"' + str(\n",
    "            title) + '\", use the delimiter \"\\n\\n==COMMENT==\\n\\n\" to distinguish individual comments. Your goal is to write sentiment analysis for each comment towards the topic - \"movie Oppenheimer\", in a format RATING - KEYWORDS. Where RATING is a number from 0 to 10, with 0 representing drastically negative attitude to the topic, 10 for a drastically positive, or 5 for neutral or a comment unrelated to a topic. KEYWORDS are 2-3 words or phrases taken unchanged from a comment, which are most indicative of reasons for such attitude, separate them with a comma (,). Use a semicolon (;) as the delimiter between each comment analysis. Example: \"8 - Exciting visuals, Nolan, direction; 4 - Confusing plot, slow pacing; 5 - long duration, too many characters;\"'}]\n",
    "    delimeter = \"\\n\\n==COMMENT==\\n\\n\"\n",
    "    prompt = delimeter.join(comments)\n",
    "    prompts.append({\"role\": \"user\", \"content\": prompt})\n",
    "    chat = openai.ChatCompletion.create(model=\"gpt-3.5-turbo-16k\", messages=prompts)\n",
    "    response = chat.choices[0].message.content\n",
    "    redditSentiment.append(Post(title, response.split(';'), prompt))\n",
    "    iter += 1\n",
    "    print(str(iter) + \"/\" + str(len(comments_by_post)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-30T20:04:39.119373Z",
     "end_time": "2023-08-30T20:06:10.670988Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "rating = 0\n",
    "keywords = dict()\n",
    "for rPost in redditSentiment:\n",
    "    tempRating = 0\n",
    "    for com in rPost.analysis:\n",
    "        if len(com) <= 3:\n",
    "            continue\n",
    "        numbers = re.findall(r'\\d+', com)\n",
    "        if len(numbers) > 0:\n",
    "            tempRating += int(numbers[0])\n",
    "        kwords = com.replace(\"\\n\", \"\").split(' - ')[1]\n",
    "        kwords = kwords.split(',')\n",
    "        kwords = [i.strip(\" \") for i in kwords]\n",
    "        for i in kwords:\n",
    "            tmp = i.strip(\" \").lower()\n",
    "            if tmp in keywords:\n",
    "                keywords[tmp] += 1\n",
    "            else:\n",
    "                keywords[tmp] = 1\n",
    "    tempRating /= len(rPost.analysis)\n",
    "    rating += tempRating\n",
    "rating /= len(redditSentiment)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-30T23:17:25.212636Z",
     "end_time": "2023-08-30T23:17:25.229681Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "srted = list(reversed(sorted(keywords.items(), key=lambda item: item[1])))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-30T23:17:29.681702Z",
     "end_time": "2023-08-30T23:17:29.699282Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margot Robbie vs mass destruction weapons.\n",
      "\n",
      "==COMMENT==\n",
      "\n",
      "Atomic bomb and blonde bombshell. I am become Doll, destroyer of young girls self image.\n",
      "\n",
      "==COMMENT==\n",
      "\n",
      "People have waaaaaay too much time on their hands\n",
      "\n",
      "==COMMENT==\n",
      "\n",
      "‚ÄúI am become Barbie, destroyer of Ben Shapiro‚Äù\n",
      "\n",
      "==COMMENT==\n",
      "\n",
      "Osama Bin Laden and Bratz movies next year please.\n",
      "\n",
      "==COMMENT==\n",
      "\n",
      "Oppenheimer will stoke even more outrage once the muppets realize it doesn't actually glorify American militarism and nuclear weapons.\n",
      "\n",
      "==COMMENT==\n",
      "\n",
      "Guess which one has full frontal nudity.\n",
      "\n",
      "==COMMENT==\n",
      "\n",
      "Conservatives when a filmmaker that frequently discusses feminism in her films discusses feminism in her films: ü§Øü§Ø\n",
      "\n",
      "==COMMENT==\n",
      "\n",
      "Ah yes, one of the most politcal controversy: plastic\n",
      "\n",
      "==COMMENT==\n",
      "\n",
      "Weirdly both of them.\n",
      "\n",
      "==COMMENT==\n",
      "\n",
      "Shouldn't have touched east Vietnam/ west Philippines sea.\n",
      "\n",
      "==COMMENT==\n",
      "\n",
      "Can we stop pretending that this is \"political outrage\"? The right wing grifters probably made their review videos after the first trailer dropped.\n",
      "\n",
      "==COMMENT==\n",
      "\n",
      "I think Greta Gerwig, Noah Baumbach and Margot Robbie would all disagree that it's really about a plastic doll. Haven't seen the film but from what I've heard it does make some social statements about feminism and the patriarchy. Not defending the outrage merchants but it's disingenuous to pretend it's really a film about a doll.\n",
      "\n",
      "==COMMENT==\n",
      "\n",
      "what outrage? I only ever see posts on this subreddit complaining about anti-barbie people but I never see anti-barbie posts\n",
      "\n",
      "==COMMENT==\n",
      "\n",
      "Saying Barbie is about a plastic doll is like saying Schindler's list is about a factory.\n",
      "\n",
      "Totally disingenuous.\n",
      "\n",
      "==COMMENT==\n",
      "\n",
      "To be fair Barbie is way more political than what you'd expect from a movie \"about a plastic doll\"\n"
     ]
    }
   ],
   "source": [
    "print(redditSentiment[1].raw)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-30T23:32:47.294561Z",
     "end_time": "2023-08-30T23:32:47.314692Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7 - destroyer of young girls self image, Doll', ' 5 - too much time', ' 6 - destroyer of Ben Shapiro', ' 5 - Osama Bin Laden, Bratz movies', \" 9 - doesn't actually glorify American militarism and nuclear weapons\", ' 7 - full frontal nudity', ' 2 - conservatives, feminism in films', ' 5 - plastic controversy', ' 5 - unrelated', ' 6 - political controversy, east Vietnam/ west Philippines sea', ' 6 - right wing grifters, review videos', ' 7 - feminism, social statements, patriarchy', ' 4 - anti-barbie people, outrage merchants', \" 9 - Schindler's list, factory\", ' 8 - political expectations from a plastic doll', '']\n"
     ]
    }
   ],
   "source": [
    "print(redditSentiment[1].analysis)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-30T23:32:48.997834Z",
     "end_time": "2023-08-30T23:32:49.018418Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "\"Oppenheimer (2023) and Barbie (2023) open the same day. One is about the invention of the atomic bomb. The other is about a plastic doll. Guess which one stoked the most political outrage. Go on, take a wild fuckin' guess\""
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditSentiment[1].title"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-30T23:32:58.829153Z",
     "end_time": "2023-08-30T23:32:58.876794Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "prompts = [{\"role\": \"system\", \"content\":\n",
    "    'You are a software development specialist'}]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-12T13:18:02.700645Z",
     "end_time": "2023-09-12T13:18:02.708644Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "To get the subtitles (also known as closed captions) for a YouTube video, `captions().list` method provided by Youtube Data API v3 can be used. \n\nFor more details, check the official YouTube API documentation: https://developers.google.com/youtube/v3/docs/captions\n\nHowever, please note that not all videos have available closed captions, and some may have multiple sets of captions in different languages. You can specify the language of the subtitle that you want.\n\nBut it's important to note that downloading YouTube captions requires proper authorization with OAuth 2.0 using the 'https://www.googleapis.com/auth/youtube.force-ssl' scope.\n\nHere is a simple demonstration code. But remember, for proper OAuth 2.0 setup and usage, please refer to the official Google OAuth 2.0 guide:\n\n```python\nfrom googleapiclient.errors import HttpError\nfrom googleapiclient.http import MediaIoBaseDownload\nfrom google.oauth2.credentials import Credentials\nimport os\nimport io\n\n# Load credentials from the 'token.json' file\ncreds = Credentials.from_authorized_user_file('token.json')\n\nyoutube = build('youtube', 'v3', credentials=creds)\n\ndef get_captions(youtube, video_id):\n    try:\n        # Retrieve caption tracks list\n        captions = youtube.captions().list(\n            part=\"snippet\",\n            videoId=video_id\n        ).execute()\n\n        # Select the first caption track\n        caption = captions['items'][0]\n\n        # Download the caption track in the language you want\n        subtitle = youtube.captions().download(\n            id=caption['id'],\n            tfmt='srt' # VTT or SRT subtitle formats.\n        ).execute()\n\n        # Save the subtitle to a .srt (or .vtt) file\n        with open(\"subtitle.srt\", \"w\", encoding=\"utf-8\") as f:\n            f.write(subtitle)\n\n        print(\"Subtitle has been written to subtitle.srt\")\n\n    except HttpError as e:\n        print(f\"A HTTP error {e.resp.status} occurred:\\n{e.content}\")\n\nget_captions(youtube, 'VIDEO_ID') # place your video id here\n```\n\nIn the code snippet above:\n\n1. We are loading the user credentials from 'token.json'. You should replace this with the path to your OAuth 2.0 credentials file. You can generate this file using Google's OAuth 2.0 Playground and save it to your script's directory.\n\n2. You need to replace \"VIDEO_ID\" with your actual video ID.\n\nPlease keep in mind that reading the captions of a Youtube video with the API costs 200 quota units, and writing a simple list operation costs 50. Always be mindful of Google's daily quota limits when using their API services."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = input()\n",
    "prompts.append({\"role\": \"user\", \"content\": prompt})\n",
    "chat = openai.ChatCompletion.create(model=\"gpt-4\", messages=prompts)\n",
    "response = (chat.choices[0].message.content)\n",
    "display(Markdown(response))\n",
    "prompts.append({\"role\": \"assistant\", \"content\": response})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-12T16:28:07.631697Z",
     "end_time": "2023-09-12T16:29:22.184252Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "To get the IDs of all Youtube videos from a specific channel, you can use the YouTube API with the Google API client for Python. Here's a basic script to get you started:\n\n```python\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\napi_key = 'YOUR_API_KEY' # replace with your own API key\nyoutube = build('youtube', 'v3', developerKey=api_key)\n\ndef get_channel_videos(channel_id):\n    res = youtube.channels().list(id=channel_id, part='contentDetails').execute()\n    playlist_id = res['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n\n    videos = []\n    next_page_token = None\n\n    while 1:\n        res = youtube.playlistItems().list(playlistId=playlist_id, \n                                           part='snippet', \n                                           maxResults=50,\n                                           pageToken=next_page_token).execute()\n        videos += res['items']\n        next_page_token = res.get('nextPageToken')\n\n        if next_page_token is None:\n            break\n\n    return videos\n\nvideos = get_channel_videos('CHANNEL_ID') # replace with the channel id \nvideo_ids = list(map(lambda x:x['snippet']['resourceId']['videoId'], videos))\n\nprint(\"\\n\".join(video_ids))\n```\n\nThis script will retrieve all the videos from the specified channel's Uploads playlist, then extract the video ID from each video in that playlist.\n\nImportant points to note:\n- Replace `'YOUR_API_KEY'` with your actual API key that you obtained from the Google Developer Console.\n- Replace `'CHANNEL_ID'` with the ID of the YouTube Channel from which you want to fetch all video IDs.\n- API quotas mean you can only make a certain number of requests per day - if you are exceeding your quota, you may need to wait, or request additional quota.\n- Depending on the number of videos, fetching all video IDs might take some time. If request times out or you encounter a similar problem, consider fetching in batches or using pagination.\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(prompts[2]['content']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-12T15:36:18.128310Z",
     "end_time": "2023-09-12T15:36:18.192309Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
